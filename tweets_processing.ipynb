{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>CSIS 452 - Applied Machine Learning</center>\n",
    "## Assignment 1 - due: 2/13/2020\n",
    "In this assignment you will develop a program using python to perform basic processing of tweets. Attached, you will find a text file named <b>apes_movies.txt</b> with tweets about the <b>Planet of the Apes</b> movie. Each line of the file holds one tweet. The tweets in the file have additional information that are not relevant to this assignment and will need to be removed. Once complete, your code will find the number of occurrence of a set of words in the tweets.  \n",
    "\n",
    "You will use incremental development to accomplish this task. Please implement the code one step at a time; and thoroughly test that step before moving to the next step.\n",
    "\n",
    "Enter your name as a comment in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Developer: Brady Lange\n",
    "# Date: 02/12/2020\n",
    "# Course: Applied Machine Learning (CSIS 452)\n",
    "# Description: Processes tweets, counts various word occurrences\n",
    "#              in tweets, serializes data, loads serialized\n",
    "#              data back into a non-serialized format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will first need to load the tweets from the file. To do this, develop a function named <b>`load_tweets`</b> that takes the name of the file as input and returns a list, where each element of the list is a line of the <b>apes_movies.txt</b> file. Make sure to use context management for handling the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Explore Data\n",
    "# =============================================================================\n",
    "def load_tweets(file):\n",
    "    '''\n",
    "    Loads specified file and reads the file by each line into a list.\n",
    "    \n",
    "    @param file  the location of the file to be loaded\n",
    "    \n",
    "    @return  each line of the file converted into a list\n",
    "\n",
    "    @version  1.0.0, 02/10/2020\n",
    "    @since  1.0, 02/10/2020\n",
    "    '''\n",
    "    # Open input file to be read\n",
    "    with open(file, \"r\") as f:\n",
    "        # Read file line by line\n",
    "        tweets = f.readlines()\n",
    "    # Return the tweets in a list\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the method developed in the last step to load the tweets from the file <b>apes_movies.txt</b> and save the list as <b>`tweets_and_more`</b>. Your code should then print the first three tweets in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Three Tweets and Extra Information:\n",
      "**********************************************************************\n",
      "2014 07 09 01 00 07 <tweet>#DawnofthePlanetoftheApes - Movie Reviews, Movie Rating, Trailers, Posters | MovieMagik http://t.co/lYSGCB8jXR via @moviemagikin</tweet> <pos>vvi vvi n2 - uh vvz , vvi vvg , n2 , n2 sy n1 n1 n1 c-acp fw-fr zz sy sy crd crd sy fw-la n1</pos> <lemmas>dawnofthe planetofthe ape - movie review , movie rate , trailer , poster | movie magik htthappy// t.co/l y s g c b8j x r via @moviemagikin</lemmas> 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 128 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 1 0 0\n",
      "\n",
      "2014 07 09 01 15 11 <tweet>Saw the new Planet of the Apes.  Best one since the original with way better effects!  #DawnofthePlanetoftheApes</tweet> <pos>vvd dt j n1 pp-f dt n2 . av-js pi c-acp dt n-jn pp n1 jc n2 ! np1</pos> <lemmas>saw the new Planet of the apes . best one since the original with way good effect ! #DawnofthePlanetoftheApes</lemmas> 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 112 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 10 0 1 5\n",
      "\n",
      "2014 07 09 01 15 21 <tweet>I could say I'm watching Planet of the Apes (1968) as a countdown to #DawnofthePlanetoftheApes - but really, I could watch it any time.</tweet> <pos>pns11 vmd vvi pns11|vbm vvg n1 pp-f dt n2 ( crd ) p-acp dt j p-acp np1 - cc-acp av-j , pns11 vmd vvi pn31 d n1 .</pos> <lemmas>I can say i'm watch Planet of the apes ( 1968 ) as a countdown to #DawnofthePlanetoftheApes - but real , I can watch it any time .</lemmas> 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 135 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 10 0 2 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load tweets and extra information\n",
    "tweets_and_more = load_tweets(\"./data/apes_movies.txt\")\n",
    "\n",
    "# Display firt three tweets and extra information\n",
    "print(\"First Three Tweets and Extra Information:\")\n",
    "print(\"**********************************************************************\")\n",
    "print(\"{0}\\n\\n{1}\\n\\n{2}\\n\\n\".format(tweets_and_more[0].strip(), \n",
    "                                     tweets_and_more[1].strip(), \n",
    "                                     tweets_and_more[2].strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output:\n",
    "\n",
    "2014 07 09 01 00 07 <tweet>#DawnofthePlanetoftheApes - Movie Reviews, Movie Rating, Trailers, Posters | MovieMagik http://t.co/lYSGCB8jXR via @moviemagikin</tweet> <pos>vvi vvi n2 - uh vvz , vvi vvg , n2 , n2 sy n1 n1 n1 c-acp fw-fr zz sy sy crd crd sy fw-la n1</pos> <lemmas>dawnofthe planetofthe ape - movie review , movie rate , trailer , poster | movie magik htthappy// t.co/l y s g c b8j x r via @moviemagikin</lemmas> 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 128 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 1 0 0\n",
    "\n",
    " 2014 07 09 01 15 11 <tweet>Saw the new Planet of the Apes.  Best one since the original with way better effects!  #DawnofthePlanetoftheApes</tweet> <pos>vvd dt j n1 pp-f dt n2 . av-js pi c-acp dt n-jn pp n1 jc n2 ! np1</pos> <lemmas>saw the new Planet of the apes . best one since the original with way good effect ! #DawnofthePlanetoftheApes</lemmas> 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 112 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 10 0 1 5\n",
    "\n",
    " 2014 07 09 01 15 21 <tweet>I could say I'm watching Planet of the Apes (1968) as a countdown to #DawnofthePlanetoftheApes - but really, I could watch it any time.</tweet> <pos>pns11 vmd vvi pns11|vbm vvg n1 pp-f dt n2 ( crd ) p-acp dt j p-acp np1 - cc-acp av-j , pns11 vmd vvi pn31 d n1 .</pos> <lemmas>I can say i'm watch Planet of the apes ( 1968 ) as a countdown to #DawnofthePlanetoftheApes - but real , I can watch it any time .</lemmas> 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 135 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 10 0 2 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code should next find the number of tweets in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tweets:\n",
      "**********************************************************************\n",
      "5823 tweets\n"
     ]
    }
   ],
   "source": [
    "# Display the number of tweets in the file\n",
    "print(\"Total Tweets:\")\n",
    "print(\"**********************************************************************\")\n",
    "print(len(tweets_and_more), \"tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output:\n",
    "5823"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the tweets, the lines of the <b>apes_movies.txt</b> have additional information that need to be removed. To do this, you will first develop a function that given an element of the <b>`tweet_and_more list`</b>, it would extract and return the tweet. Note that tweets are enclosed in the markups <b>&lt;`tweet`&gt;</b> and <b>&lt;`/tweet`&gt;</b>.  \n",
    "\n",
    "<b>HINT:</b> Use the Python's `index()` function to identify the index of <b>&lt;`tweet`&gt;</b> and <b>&lt;`/tweet`&gt;</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Data\n",
    "# =============================================================================\n",
    "def extract_tweet(index):\n",
    "    '''\n",
    "    Takes an index from a list and extracts just the tweet portion\n",
    "    of that index and returns the tweet.\n",
    "    \n",
    "    @param index  the location inside of the list\n",
    "    \n",
    "    @return  tweet from that index\n",
    "\n",
    "    @version  1.0.0, 02/10/2020\n",
    "    @since  1.0, 02/10/2020\n",
    "    '''\n",
    "    # Tweet start markup tag\n",
    "    tweet_tag_start = \"<tweet>\"\n",
    "    # Tweet end markup tag\n",
    "    tweet_tag_end = \"</tweet>\"\n",
    "    # Retrieve where the tweet begins, add the length of the start tweet tag\n",
    "    start_index = tweets_and_more[index].index(tweet_tag_start) + len(tweet_tag_start)\n",
    "    # Retrieve where the tweet ends\n",
    "    end_index = tweets_and_more[index].index(tweet_tag_end)\n",
    "    # Extract the tweet from specified location in the list\n",
    "    tweet = tweets_and_more[index][start_index:end_index]\n",
    "    # Return the extracted tweet\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the <b>`extract_tweet`</b> function of the last step to extract and print the tweet from the first tweet in <b>`tweets_and_more`</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Tweet:\n",
      "**********************************************************************\n",
      "#DawnofthePlanetoftheApes - Movie Reviews, Movie Rating, Trailers, Posters | MovieMagik http://t.co/lYSGCB8jXR via @moviemagikin\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the first tweet in the list\n",
    "first_tweet = extract_tweet(0)\n",
    "\n",
    "# Display the first tweet in the list\n",
    "print(\"First Tweet:\")\n",
    "print(\"**********************************************************************\")\n",
    "print(first_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output:\n",
    "\\#DawnofthePlanetoftheApes - Movie Reviews, Movie Rating, Trailers, Posters | MovieMagik http://t.co/lYSGCB8jXR via @moviemagikin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using list comprehension to extract all the tweets in the <b>`tweets_and_more`</b> list and save them in another list called <b>`tweets`</b>. Print the length of the resulting list. Also, print the first three elements of the new list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tweets:\n",
      "**********************************************************************\n",
      "5823 tweets\n",
      "\n",
      "First Three Tweets:\n",
      "**********************************************************************\n",
      "#DawnofthePlanetoftheApes - Movie Reviews, Movie Rating, Trailers, Posters | MovieMagik http://t.co/lYSGCB8jXR via @moviemagikin\n",
      "\n",
      "Saw the new Planet of the Apes.  Best one since the original with way better effects!  #DawnofthePlanetoftheApes\n",
      "\n",
      "I could say I'm watching Planet of the Apes (1968) as a countdown to #DawnofthePlanetoftheApes - but really, I could watch it any time.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List comprehension to extract all of the tweets in the list\n",
    "tweets = [extract_tweet(i) for i in range(len(tweets_and_more))]\n",
    "\n",
    "# Display the length of the tweets extracted from the list\n",
    "print(\"Total Tweets:\")\n",
    "print(\"**********************************************************************\")\n",
    "print(len(tweets), \"tweets\\n\")\n",
    "\n",
    "# Display the first three tweets\n",
    "print(\"First Three Tweets:\")\n",
    "print(\"**********************************************************************\")\n",
    "print(\"{0}\\n\\n{1}\\n\\n{2}\\n\\n\".format(tweets[0], tweets[1], tweets[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output:\n",
    "5823\n",
    "\n",
    "\\#DawnofthePlanetoftheApes - Movie Reviews, Movie Rating, Trailers, Posters | MovieMagik http://t.co/lYSGCB8jXR via @moviemagikin\n",
    "\n",
    "Saw the new Planet of the Apes.  Best one since the original with way better effects!  #DawnofthePlanetoftheApes\n",
    "\n",
    "I could say I'm watching Planet of the Apes (1968) as a countdown to #DawnofthePlanetoftheApes - but really, I could watch it any time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now develop a function called <b>`count_this_word_in_this_tweet`</b> that takes as input a tweet and a word and it would return the number of times the word occurs in the tweet. Your function should be case-insensitive.  \n",
    "\n",
    "<b>HINT:</b> Use the `split()` and `count()` methods of Python strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Occurences Analysis\n",
    "# =============================================================================\n",
    "def count_this_word_in_this_tweet(tweet, word):\n",
    "    '''\n",
    "    Takes a tweet and a word for input and counts how\n",
    "    many times that word appears in the tweet no \n",
    "    matter the case.\n",
    "    \n",
    "    @param tweet  tweet string\n",
    "    @param word  word to be counted\n",
    "    \n",
    "    @return  how many times the word appears in the\n",
    "             tweet\n",
    "\n",
    "    @version  1.0.0, 02/10/2020\n",
    "    @since  1.0, 02/10/2020\n",
    "    '''\n",
    "    # Convert tweet/word to lowercase, split each word, count total of word\n",
    "    word_count = tweet.lower().split().count(word.lower())\n",
    "    # Return how many times the word appeared in the tweet\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function developed in the last step to find and print the number of occurrence of the word <b>movie</b> in in the first tweet in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Occurences in a Tweet:\n",
      "**********************************************************************\n",
      "In the tweet:\n",
      "#DawnofthePlanetoftheApes - Movie Reviews, Movie Rating, Trailers, Posters | MovieMagik http://t.co/lYSGCB8jXR via @moviemagikin, the word 'movie' appears 2 times.\n"
     ]
    }
   ],
   "source": [
    "# First tweet\n",
    "tweet = tweets[0]\n",
    "# Word to search for amount of occurences\n",
    "word = \"movie\"\n",
    "\n",
    "# Retrieve the amount of times the word appears in the tweet\n",
    "movie_word_count = count_this_word_in_this_tweet(tweet, word)\n",
    "\n",
    "# Display how many times the word appears in the tweet\n",
    "print(\"Word Occurences in a Tweet:\")\n",
    "print(\"**********************************************************************\")\n",
    "print(\"In the tweet:\\n\" + tweet + \", the word '\" + word \n",
    "      + \"' appears \" + str(movie_word_count) + \" times.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output:\n",
    "2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now develop a function called <b>`count_this_word_in_all_tweets`</b> that takes as arguments a list of tweets and a word and it would find the number of occurrence of the word in all tweets in the list. The function should use list comprehension and the function <b>`count_this_word_in_this_tweet`</b> defined earlier to accomplish its task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_this_word_in_all_tweets(tweets, word):\n",
    "    '''\n",
    "    Takes a list of tweets and a word for input and counts how\n",
    "    many times that word appears in all of the tweets no \n",
    "    matter the case.\n",
    "    \n",
    "    @param tweets  list of tweets\n",
    "    @param word  word to be counted\n",
    "    \n",
    "    @return  how many times the word appears in all of the\n",
    "             tweets\n",
    "\n",
    "    @version  1.0.0, 02/10/2020\n",
    "    @since  1.0, 02/10/2020\n",
    "    '''\n",
    "    # List comprehension that adds the amount of all word occurrences\n",
    "    word_count = sum([count_this_word_in_this_tweet(i, word) for i in tweets])\n",
    "    # Return the amount of the word occurences in all of the tweets\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function developed in the last step to find and print the number of occurrence of the word <b>movie</b> in in all the tweets in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Occurences in All of the Tweets:\n",
      "**********************************************************************\n",
      "In all of the tweets, the word 'movie' appears 156 times.\n"
     ]
    }
   ],
   "source": [
    "# Word to be searched for amount of occurences\n",
    "word = \"movie\"\n",
    "\n",
    "# Retrieve the amount of times the word appears in all tweets\n",
    "all_movie_word_count = count_this_word_in_all_tweets(tweets, word)\n",
    "\n",
    "# Display how many times the word appears in all tweets\n",
    "print(\"Word Occurences in All of the Tweets:\")\n",
    "print(\"**********************************************************************\")\n",
    "print(\"In all of the tweets, the word '\" + word \n",
    "      + \"' appears \" + str(all_movie_word_count) \n",
    "      + \" times.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output:\n",
    "156"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now develop a function called <b>`count_these_words_in_all_tweets`</b> that would take as its arguments a list of tweets and a variable argument list called <b>words</b>. Your function should then use dictionary comprehension to create a dictionary of words (key) and their corresponding counts (value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_these_words_in_all_tweets(tweets, *words):\n",
    "    '''\n",
    "    Takes a list of tweets and list of words for input\n",
    "    and creates a dictionary for each word of how many \n",
    "    times it appeared in the list of tweets.\n",
    "    \n",
    "    @param tweets  list of tweets\n",
    "    @param *words  words to be counted\n",
    "    \n",
    "    @return  dictionary of how many times the words \n",
    "             appear in all of the tweets\n",
    "\n",
    "    @version  1.0.0, 02/10/2020\n",
    "    @since  1.0, 02/10/2020\n",
    "    '''\n",
    "    # Dictionary comprehension with word as the key and count as the value\n",
    "    word_dict = {k:count_this_word_in_all_tweets(tweets, k) for k in words}\n",
    "    # Return the dictionary of words and counts in all of the tweets\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function developed in the last problem on the words list:\n",
    "<b>`words = [\"movie\", \"fun\", \"best\", \":)\"]`</b>. Save the returned dictionary in the <b>`word_count_dict`</b> and then print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Word Occurences in All of the Tweets:\n",
      "**********************************************************************\n",
      "{'movie': 156, 'fun': 4, 'best': 87, ':)': 28}\n"
     ]
    }
   ],
   "source": [
    "# Words to be searched for amount of occurences\n",
    "words = [\"movie\", \"fun\", \"best\", \":)\"]\n",
    "\n",
    "# Retrieve the amount of times the words appear in all tweets\n",
    "word_count_dict = count_these_words_in_all_tweets(tweets, \n",
    "                                                  words[0], \n",
    "                                                  words[1], \n",
    "                                                  words[2], \n",
    "                                                  words[3])\n",
    "\n",
    "# Display how many times the words appear in all tweets\n",
    "print(\"Multiple Word Occurences in All of the Tweets:\")\n",
    "print(\"**********************************************************************\")\n",
    "print(str(word_count_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output:\n",
    "{'movie': 156, 'fun': 4, 'best': 87, ':)': 28}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the <b>`word_count_dict`</b> in a `pickle` file called <b>`tweet_word_count.pickle`</b>. Be sure to use context management for handling files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialization:\n",
      "**********************************************************************\n",
      "Serializing data...\n",
      "Data serialized...\n"
     ]
    }
   ],
   "source": [
    "# Serialize Data\n",
    "# =============================================================================\n",
    "print(\"Serialization:\")\n",
    "print(\"**********************************************************************\")\n",
    "print(\"Serializing data...\")\n",
    "# Open file to write in binary mode\n",
    "with open(\"./data/tweet_word_count.pickle\", \"wb\") as f:\n",
    "    # Dump the word dictionary into a pickle file\n",
    "    pickle.dump(word_count_dict, f)\n",
    "print(\"Data serialized...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, load and display the dictionary saved in the file <b>`tweet_word_count.pickle`</b>. Be sure to use context management for handling files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unserialization:\n",
      "**********************************************************************\n",
      "Data loaded...\n",
      "\n",
      "{'movie': 156, 'fun': 4, 'best': 87, ':)': 28}\n"
     ]
    }
   ],
   "source": [
    "# Unserialize Data\n",
    "# =============================================================================\n",
    "print(\"Unserialization:\")\n",
    "print(\"**********************************************************************\")\n",
    "# Open file to be read in binary mode\n",
    "with open(\"./data/tweet_word_count.pickle\", \"rb\") as f:\n",
    "    # Load the pickle file\n",
    "    word_count_dict = pickle.load(f)\n",
    "print(\"Data loaded...\\n\")\n",
    "    \n",
    "# Display how many times the words appear in all tweets\n",
    "print(str(word_count_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output:\n",
    "{'movie': 156, 'fun': 4, 'best': 87, ':)': 28}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
